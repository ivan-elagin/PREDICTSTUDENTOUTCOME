{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, label_binarize\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score, make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import mrmr\n",
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "import plotly as pio\n",
    "import logging\n",
    "from mrmr import mrmr_classif\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters specific to models, to ensure Optuna searches for correct parameters, when model is changed\n",
    "model_param_spaces = {\n",
    "    'RandomForestClassifier': {\n",
    "        \"n_estimators\": (100, 1000),\n",
    "        \"max_depth\": (10, 100),\n",
    "        \"min_samples_split\": (2, 20),\n",
    "        \"min_samples_leaf\": (1, 10),\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": (0.01, 100.0),\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"max_depth\": (10, 100),\n",
    "        \"min_samples_split\": (2, 20),\n",
    "        \"min_samples_leaf\": (1, 10),\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"C\": (0.01, 100.0),\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        \"degree\": (2, 5), \n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ml_model, use_optuna, use_feature_selection, remove_enrolled_class, remove_sem2_data, use_encoding, class_weight=\"balanced\"):\n",
    "\n",
    "    # Constants\n",
    "    categorical_features = [\"Marital status\", \"Displaced\", \"Educational special needs\", \"Debtor\", \"Tuition fees up to date\", \"Gender\", \"Scholarship holder\", \"International\", \n",
    "                            \"Application mode\", \"Daytime/evening attendance\\t\", \"Previous qualification\", \"Nacionality\", \"Mother's qualification\", \"Father's qualification\",\n",
    "                            \"Mother's occupation\", \"Father's occupation\"]\n",
    "    \n",
    "    numeric_features = [\"Application order\", \"Previous qualification (grade)\", \"Admission grade\", \"Age at enrollment\", \"GDP\", \"Inflation rate\", \"Curricular units 1st sem (credited)\", \"Curricular units 1st sem (enrolled)\", \"Curricular units 1st sem (evaluations)\", \n",
    "                    \"Curricular units 1st sem (approved)\", \"Curricular units 1st sem (without evaluations)\", \"Curricular units 1st sem (grade)\", \"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (enrolled)\", \"Curricular units 2nd sem (evaluations)\", \n",
    "                    \"Curricular units 2nd sem (approved)\", \"Curricular units 2nd sem (grade)\", \"Curricular units 2nd sem (without evaluations)\"]\n",
    "    \n",
    "    cat_columns_to_one_hot = [\"Course\"]\n",
    "\n",
    "    # The main pipeline\n",
    "    df = pd.read_csv(\"/Users/elaginivan/CODING/STUDENT_DATASET.csv\", delimiter=\";\")\n",
    "    target_colname = \"Target\"\n",
    "\n",
    "    y_test, y_prediction, y_score = pipeline(df=df, target_colname=target_colname, categorical_features=categorical_features, numeric_features=numeric_features,\n",
    "                                    cat_columns_to_one_hot=cat_columns_to_one_hot, ml_model=ml_model, use_optuna=use_optuna, use_feature_selection=use_feature_selection, \n",
    "                                    remove_enrolled_class=remove_enrolled_class, remove_sem2_data=remove_sem2_data, use_encoding=use_encoding, class_weight=class_weight) \n",
    "\n",
    "    visualize_results(y_test, y_prediction)\n",
    "    \n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_prediction))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_prediction))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_prediction))\n",
    "    \n",
    "    unique_classes = np.unique(y_test)\n",
    "    y_test_binarized = label_binarize(y_test, classes=unique_classes)\n",
    "    n_classes = y_test_binarized.shape[1]\n",
    "    \n",
    "    # Plotting the ROC curve\n",
    "    if n_classes == 2 or n_classes == 1:  # Binary classification scenario\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        print(f\"ROC AUC score: {roc_auc:.3f}\")\n",
    "        \n",
    "    else:  # Multi-class scenario\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i, class_label in enumerate(unique_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure()\n",
    "        colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Multi-class ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate and print multi-class ROC AUC scores\n",
    "        roc_auc_ovr = roc_auc_score(y_test_binarized, y_score, multi_class=\"ovr\", average=\"macro\")\n",
    "        print(f\"Overall ROC AUC Score (One-vs-Rest): {roc_auc_ovr:.3f}\")\n",
    "        roc_auc_ovo = roc_auc_score(y_test_binarized, y_score, multi_class=\"ovo\", average=\"macro\")\n",
    "        print(f\"Overall ROC AUC Score (One-vs-One): {roc_auc_ovo:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test, categorical_features, numeric_features, cat_columns_to_one_hot, use_encoding):\n",
    "\n",
    "    if not use_encoding:\n",
    "        return train, test\n",
    "\n",
    "    # Processing numerical features\n",
    "    for num_feature in numeric_features:\n",
    "        scaler = StandardScaler()\n",
    "        train[num_feature] = scaler.fit_transform(train[[num_feature]])\n",
    "        test[num_feature] = scaler.transform(test[[num_feature]])\n",
    "\n",
    "    # Processing categorical features not in one-hot encoding list\n",
    "    for cat_feature in [cf for cf in categorical_features if cf not in cat_columns_to_one_hot]:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on the combined set of train and test data to ensure consistency\n",
    "        le.fit(pd.concat([train[cat_feature], test[cat_feature]], axis=0, ignore_index=True))\n",
    "        train[cat_feature] = le.transform(train[cat_feature])\n",
    "        test[cat_feature] = le.transform(test[cat_feature])\n",
    "\n",
    "    # One-hot encoding specified categorical features\n",
    "    for cat_feature in cat_columns_to_one_hot:\n",
    "        ohe = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")\n",
    "    \n",
    "        train_encoded = ohe.fit_transform(train[[cat_feature]]).toarray()\n",
    "        test_encoded = ohe.transform(test[[cat_feature]]).toarray()\n",
    "    \n",
    "        # Generating feature names for the one-hot encoded columns\n",
    "        feature_names = ohe.get_feature_names_out([cat_feature])\n",
    "        \n",
    "        # Updating the DataFrame with the new columns\n",
    "        train = train.join(pd.DataFrame(train_encoded, index=train.index, columns=feature_names))\n",
    "        test = test.join(pd.DataFrame(test_encoded, index=test.index, columns=feature_names))\n",
    "    \n",
    "        # Dropping the original categorical column as it's now encoded\n",
    "        train.drop(columns=[cat_feature], inplace=True)\n",
    "        test.drop(columns=[cat_feature], inplace=True)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train_data, train_target, test_data, K):\n",
    "    \n",
    "    # Returns top K feature names selected using MRMR algorithm\n",
    "    \n",
    "    top_features = mrmr_classif(X=train_data, y=train_target, K=K)\n",
    "    print(f\"Top {K} features selected by MRMR:\")\n",
    "    for feature in top_features:\n",
    "        print(feature)\n",
    "    return train_data[top_features], test_data[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_function(train_data, train_target, ml_model_name, n_trials=100):\n",
    "    \n",
    "    # Fetching the parameter space for the model\n",
    "    param_space = model_param_spaces[ml_model_name]\n",
    "    \n",
    "    # Objective function for Optuna optimization\n",
    "    def objective(trial): \n",
    "        params = {}\n",
    "        for param_name, param_range in param_space.items():\n",
    "            # Parameter suggestions based on type\n",
    "            if param_name == \"C\":\n",
    "                params[param_name] = trial.suggest_loguniform(param_name, param_range[0], param_range[1])\n",
    "            elif isinstance(param_range, list):\n",
    "                params[param_name] = trial.suggest_categorical(param_name, param_range)\n",
    "            elif param_name in [\"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"n_estimators\", \"n_neighbors\", \"degree\"]:\n",
    "                if len(param_range) == 3:\n",
    "                    params[param_name] = trial.suggest_int(param_name, param_range[0], param_range[1], step=param_range[2])\n",
    "                else:\n",
    "                    params[param_name] = trial.suggest_int(param_name, param_range[0], param_range[1])\n",
    "            else:\n",
    "                params[param_name] = trial.suggest_float(param_name, param_range[0], param_range[1])\n",
    "\n",
    "        # Model class evaluation from string\n",
    "        model_class = eval(ml_model_name)\n",
    "\n",
    "        # Conditionally adding random_state only if supported by the model\n",
    "        model_params = params.copy()  # Make a copy of the parameters\n",
    "        if \"random_state\" in model_class().get_params():\n",
    "            model_params[\"random_state\"] = 42\n",
    "        \n",
    "        # Adding optimal parameters to the model\n",
    "        model = model_class(**model_params)\n",
    "\n",
    "        # Scoring and cross-validation setup\n",
    "        scorer = make_scorer(f1_score, average=\"macro\")\n",
    "        cv_strategy = StratifiedKFold(n_splits=5)\n",
    "        score = cross_val_score(model, train_data, train_target, scoring=scorer, cv=cv_strategy, n_jobs=-1).mean()\n",
    "        return score\n",
    "\n",
    "    # Optuna study and optimization\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # Contout plot for visualization\n",
    "    contplot = optuna.visualization.plot_contour(study)\n",
    "    contplot.update_layout(font=dict(size=14), xaxis_title_font=dict(size=14), yaxis_title_font=dict(size=14), width=2000, height=1500)\n",
    "    contplot.show()\n",
    "    \n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    return study.best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, target_colname, categorical_features, numeric_features, cat_columns_to_one_hot, remove_enrolled_class, remove_sem2_data, ml_model, use_optuna, use_feature_selection, use_encoding, class_weight, n_trials=100):\n",
    "    \n",
    "    df = df[df['Course'] != 171]\n",
    "    \n",
    "    if remove_enrolled_class:\n",
    "        df = df[df[target_colname] != \"Enrolled\"] # Removing 'Enrolled' class from the dataset\n",
    "        \n",
    "    sem2_columns = [\"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (enrolled)\", \"Curricular units 2nd sem (evaluations)\", \n",
    "                    \"Curricular units 2nd sem (approved)\", \"Curricular units 2nd sem (grade)\", \"Curricular units 2nd sem (without evaluations)\"]\n",
    "\n",
    "    if remove_sem2_data:\n",
    "        df = df.drop(sem2_columns, axis=1)\n",
    "        # Also removing these columns from the numeric_features list to avoid the KeyError\n",
    "        numeric_features = [nf for nf in numeric_features if nf not in sem2_columns]\n",
    "                \n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"Target_encoded\"] = label_encoder.fit_transform(df[target_colname]) # 0 - dropout, 1 - enrolled, 2 - graduate\n",
    "    y = df[\"Target_encoded\"]\n",
    "    X = df.drop([\"Target\", \"Target_encoded\"], axis=1)\n",
    "    \n",
    "    # Splitting the data into train and test sets prior to preprocessing to avoid data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Preprocessing the data separately for train and test sets\n",
    "    X_train, X_test = preprocess(X_train, X_test, categorical_features, numeric_features, cat_columns_to_one_hot, use_encoding)\n",
    "    \n",
    "    # Oversampling the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Feature selection using MRMR algorithm\n",
    "    if use_feature_selection: \n",
    "        K = 10\n",
    "        X_train, X_test = feature_selection(X_train, y_train, X_test, K)\n",
    "    \n",
    "    # Optuna hyperparameter optimization\n",
    "    best_params = {} \n",
    "    if use_optuna:  \n",
    "        best_params = optimize_function(X_train, y_train, ml_model.__name__, n_trials)\n",
    "    else:\n",
    "        best_params = {}\n",
    "    \n",
    "    model_params = best_params\n",
    "    if hasattr(ml_model(), \"random_state\"):  # Check if the model supports \"random_state\"\n",
    "        model_params[\"random_state\"] = 42\n",
    "    \n",
    "    # Using the model without class_weight for models that do not support it\n",
    "    if \"class_weight\" in ml_model().get_params():\n",
    "        model = ml_model(class_weight=class_weight, **model_params)\n",
    "    else:\n",
    "        model = ml_model(**model_params)\n",
    "\n",
    "    # Model training\n",
    "    model.fit(X_train, y_train) \n",
    "    y_prediction = model.predict(X_test)\n",
    "    y_score = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    return y_test, y_prediction, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(y_test, y_prediction):\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_prediction) # Confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  \n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues) \n",
    "    plt.title(\"Confusion Matrix\", pad=20, fontsize=20)\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    plt.xlabel(\"Predicted\", fontsize=14) \n",
    "    plt.ylabel(\"True\", fontsize=14)   \n",
    "    plt.xticks(np.arange(len(np.unique(y_test))), np.unique(y_test), rotation=90)\n",
    "    plt.yticks(np.arange(len(np.unique(y_test))), np.unique(y_test))\n",
    "    \n",
    "    for i in range(cm.shape[0]): # Adding the numbers to the confusion matrix plot\n",
    "        for j in range(cm.shape[1]): \n",
    "            ax.text(j, i, format(cm[i, j], \"d\"),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\") \n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the main function\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(ml_model=RandomForestClassifier, use_optuna=False, use_feature_selection=True, remove_enrolled_class=True, remove_sem2_data=False, use_encoding=True, class_weight=\"balanced\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
